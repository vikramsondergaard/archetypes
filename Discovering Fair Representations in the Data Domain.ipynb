{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3afa87e0",
   "metadata": {},
   "source": [
    "# Discovering Fair Representations in the Data Domain\n",
    "\n",
    "Interpretability and fairness are important in machine learning. There are many situations where a machine learning model has made unfair decisions that are difficult to interpret by either its designers or the people it affects.\n",
    "\n",
    "Quadrianto *et al.* devise a method for projecting data into a \"fair\" domain. This not only identifies areas where machine learning models might discriminate, but it also eliminates these sources of discrimination. Therefore, the problem becomes one of translating data from an input space into a \"fair\" space.\n",
    "\n",
    "[Link to paper](https://arxiv.org/abs/1810.06755)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a13caff",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Machine learning models are becoming more ubiquitous in everyday life. This includes in government and business, for purposes such as hiring candidates and giving loans. Often, these systems are not *fair*: they discriminate against individuals based on characteristics that should be \"protected\". These include gender, ethnicity and ability. Previous attempts at making machine learning models fair use *latent embeddings*. These models are difficult to interpret, as these latent embeddings are the result of complex probabilistic calculations.\n",
    "\n",
    "Quadrianto *et al.* therefore devise a machine learning model that projects data into a \"fair\" domain. This means that it is easy to interpret the modifications that have been made to the data to make it fair. The way in which they achieve this is by implementing a *data-to-data translation*. This means that the data is mapped from an input domain to a target \"fair\" domain. There are several examples of this practice: Zhu *et al.*'s [CycleGAN](https://arxiv.org/abs/1703.10593) and Choi *et al.*'s [StarGAN](https://arxiv.org/abs/1711.09020) solve this problem where only *un*aligned training examples are available. The difference in this method is that *there is no data in the target domain*. That is, fair images are not readily available, and images themselves cannot be classified as fair or unfair without prior context.\n",
    "\n",
    "As an example, consider a situation where job applicants send a photo of themselves as part of the application process. A model might achieve fairness by just *translating female faces to male ones*, but this is inherently biased towards male faces. So, to achieve fairness, there are at least *two sub-problems*:\n",
    "1. How can this method be generalised to handle both image and tabular data?\n",
    "2. How can this method find a middle-ground \"fair\" representation with potentially multi-modal protected characteristic(s)?\n",
    "\n",
    "This paper solves this problem by focusing on statistical dependence/independence between \"fair\" images and protected characteristics.\n",
    "\n",
    "#### Related work\n",
    "\n",
    "This work improves on fair *but uninterpretable* machine learning models.\n",
    "\n",
    "There are *very few*, *if any* machine learning models that are fair and also retain the semantics of the input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8b459e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os.path\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import svm\n",
    "from sklearn import model_selection as cross_validation\n",
    "import sys\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca0f80cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.13.0-cp310-cp310-macosx_10_15_x86_64.whl (216.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.2/216.2 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:05\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.1.21\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting tensorboard<2.14,>=2.13\n",
      "  Using cached tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "Collecting keras<2.14,>=2.13.1\n",
      "  Using cached keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: typing-extensions<4.6.0,>=3.6.6 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting absl-py>=1.0.0\n",
      "  Using cached absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Collecting gast<=0.4.0,>=0.2.1\n",
      "  Using cached gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.33.0-cp310-cp310-macosx_10_14_x86_64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: setuptools in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorflow) (65.6.3)\n",
      "Requirement already satisfied: packaging in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: numpy<=1.24.3,>=1.22 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting libclang>=13.0.0\n",
      "  Using cached libclang-16.0.6-py2.py3-none-macosx_10_9_x86_64.whl (24.5 MB)\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0\n",
      "  Using cached tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Using cached termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3\n",
      "  Using cached protobuf-4.24.0-cp37-abi3-macosx_10_9_universal2.whl (409 kB)\n",
      "Collecting google-pasta>=0.1.1\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.57.0.tar.gz (24.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.7/24.7 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (3.4.1)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5\n",
      "  Using cached google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Using cached tensorboard_data_server-0.7.1-py3-none-macosx_10_9_x86_64.whl (4.8 MB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.2.2)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Using cached google_auth-2.22.0-py2.py3-none-any.whl (181 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from tensorboard<2.14,>=2.13->tensorflow) (2.28.1)\n",
      "Requirement already satisfied: urllib3<2.0 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (1.26.14)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.2.8)\n",
      "Collecting cachetools<6.0,>=2.0.0\n",
      "  Using cached cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/vikramsondergaard/anaconda3/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow) (0.4.8)\n",
      "Collecting oauthlib>=3.0.0\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Building wheels for collected packages: grpcio\n",
      "  Building wheel for grpcio (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for grpcio: filename=grpcio-1.57.0-cp310-cp310-macosx_10_10_x86_64.whl size=4273361 sha256=5a4e14c3d167b9ff1ad430a3dcd684fb66c39e7034a14bf38907f4fd0cb24579\n",
      "  Stored in directory: /Users/vikramsondergaard/Library/Caches/pip/wheels/6d/fb/80/c244d0eb3892d472c21f9636a6dbf79fb69a2109e52f33ec2c\n",
      "Successfully built grpcio\n",
      "Installing collected packages: libclang, flatbuffers, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, rsa, protobuf, opt-einsum, oauthlib, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-1.4.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.22.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.57.0 keras-2.13.1 libclang-16.0.6 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.24.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-io-gcs-filesystem-0.33.0 termcolor-2.3.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839f299c",
   "metadata": {},
   "source": [
    "## Interpretability in fairness by residual decomposition\n",
    "\n",
    "Take an automated hiring algorithm as an example:\n",
    "- The input data will include photographs, work experience, education and training, personal skills, and other relevant attributes.\n",
    "- The protected characterstics can be features such as *ethnicity* or *gender*, $s^n \\in \\{A, B, C, D, ...\\}$, or *age*, $s^n \\in \\mathbb{R}$.\n",
    "\n",
    "The goal is then to train a classifier $f$ that predicts whether the company should hire the given person."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2759cd27",
   "metadata": {},
   "source": [
    "### Fairness definitions\n",
    "\n",
    "Existing papers on mathematical definitions on fairness abound, including using [disparate impact](https://arxiv.org/abs/1610.07524) and [formalised fairness conditions](https://arxiv.org/abs/1609.05807). The focus in this work is on *equality of opportunity*. This requires that $f$ and the protected characteristic $s$ be independent, conditional on the label being positive. That is, $f \\perp \\! \\! \\! \\perp s | y = +1$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18258eff",
   "metadata": {},
   "source": [
    "### Residual decomposition\n",
    "\n",
    "Goals for the data representation $\\tilde{\\mathbf{x}}^n$, given an input $\\mathbf{x}^n$:\n",
    "1. It can predict the output label $y^n$\n",
    "2. It is fair according to some criterion with respect to $s$, the protected characteristic\n",
    "3. It lies in the same space as $\\mathbf{x}^n$. So $\\tilde{\\mathbf{x}}^n \\in \\mathcal{X}$.\n",
    "\n",
    "The third goal is especially important as it provides a starting point for keeping the same *semantic meaning* between $\\mathbf{x}^n$ and $\\tilde{\\mathbf{x}}^n$. Preserving semantic meaning can only be done thanks to *observational data*: this allows one to inspect how fairness criteria, protected characteristics and classification accuracy work together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9a850e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(train_path, test_path, validation_size, random_state,\n",
    "                 data_name, feature_split, remake_test=False, test_size=None,\n",
    "                 input_scaler=StandardScaler, sensitive_scaler=None):\n",
    "    df_train_raw = pd.read_csv(train_path, engine='c')\n",
    "    df_test_raw = pd.read_csv(test_path)\n",
    "\n",
    "    if remake_test:\n",
    "        if test_size is None:\n",
    "            test_size = df_test_raw.shape[0]\n",
    "\n",
    "        df_full = pd.concat([df_train_raw, df_test_raw])\n",
    "        df_full_shuffled = df_full.sample(frac=1, random_state=random_state)\n",
    "\n",
    "        df_train_valid = df_full_shuffled[:-test_size]\n",
    "        df_test = df_full_shuffled[-test_size:]\n",
    "\n",
    "    else:\n",
    "        if test_size is not None:\n",
    "            raise ValueError(\"Changing test size is only possible \"\n",
    "                             \"if remake_test is True.\")\n",
    "\n",
    "        df_train_valid = df_train_raw.sample(frac=1, random_state=random_state)\n",
    "        df_test = df_test_raw\n",
    "\n",
    "    df_train = df_train_valid[:-validation_size]\n",
    "    df_valid = df_train_valid[-validation_size:]\n",
    "\n",
    "    x_train, s_train, y_train, cat_features = _split_features(df_train, data_name, \n",
    "                                                feature_split)\n",
    "    x_valid, s_valid, y_valid,_ = _split_features(df_valid, data_name, \n",
    "                                                feature_split)\n",
    "    x_test, s_test, y_test,_ = _split_features(df_test, data_name, \n",
    "                                             feature_split)\n",
    "\n",
    "    x_train, x_valid, x_test = scale(\n",
    "        input_scaler, x_train, x_valid, x_test)\n",
    "\n",
    "    s_train, s_valid, s_test = scale(\n",
    "        sensitive_scaler, s_train, s_valid, s_test)\n",
    "\n",
    "    data_train = x_train, s_train, y_train\n",
    "    data_valid = x_valid, s_valid, y_valid\n",
    "    data_test = x_test, s_test, y_test\n",
    "\n",
    "    return data_train, data_valid, data_test, cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "67869f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_median(v):\n",
    "    v = tf.reshape(v, [-1])\n",
    "    m = v.get_shape()[0] // 2\n",
    "    return tf.nn.top_k(v, m).values[m - 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "501ff233",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_median_pairwise_euclidean_distance(X):\n",
    "    XX = tf.matmul(X, X, transpose_b=True)\n",
    "    X_sqnorms = tf.diag_part(XX)\n",
    "    r = lambda x: tf.expand_dims(x, 0)\n",
    "    c = lambda x: tf.expand_dims(x, 1)\n",
    "    pair_dist = (-2 * XX + c(X_sqnorms) + r(X_sqnorms))\n",
    "    pair_dist = tf.nn.relu(pair_dist)\n",
    "    sq_dist = tf.sqrt(pair_dist)\n",
    "    med_sqrt = get_median(sq_dist)\n",
    "    return med_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c9c4dc72",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_euclidean_distance(data):\n",
    "    X, s, y = data\n",
    "\n",
    "    XX = np.dot(X, X.T)\n",
    "    X_sqnorms = np.diag(XX)\n",
    "    r = lambda x: np.expand_dims(x, 0)\n",
    "    c = lambda x: np.expand_dims(x, 1)\n",
    "    pair_dist = (-2 * XX + c(X_sqnorms) + r(X_sqnorms))\n",
    "    pair_dist[pair_dist < 0] = 0\n",
    "    return np.sqrt(pair_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ab62dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dense_bn_relu(inp, units, deploy):\n",
    "    units = tf.layers.dense(\n",
    "        inp, units, activation=tf.nn.relu,\n",
    "        kernel_initializer=tf.uniform_unit_scaling_initializer(seed=888))\n",
    "    return units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb1b99f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_time_HSIC(data_first, data_second, sigma_first, sigma_second):\n",
    "    XX = tf.matmul(data_first, data_first, transpose_b=True)\n",
    "    YY = tf.matmul(data_second, data_second, transpose_b=True)\n",
    "    X_sqnorms = tf.diag_part(XX)\n",
    "    Y_sqnorms = tf.diag_part(YY)\n",
    "\n",
    "    r = lambda x: tf.expand_dims(x, 0)\n",
    "    c = lambda x: tf.expand_dims(x, 1)\n",
    "\n",
    "    gamma_first = 1. / (2 * sigma_first**2)\n",
    "    gamma_second = 1. / (2 * sigma_second**2)\n",
    "    # use the second binomial formula\n",
    "    Kernel_XX = tf.exp(-gamma_first * (-2 * XX + c(X_sqnorms) + r(X_sqnorms)))\n",
    "    Kernel_YY = tf.exp(-gamma_second * (-2 * YY + c(Y_sqnorms) + r(Y_sqnorms)))\n",
    "\n",
    "    Kernel_XX_mean = tf.reduce_mean(Kernel_XX, 0, keep_dims=True)\n",
    "    Kernel_YY_mean = tf.reduce_mean(Kernel_YY, 0, keep_dims=True)\n",
    "\n",
    "    HK = Kernel_XX - Kernel_XX_mean\n",
    "    HL = Kernel_YY - Kernel_YY_mean\n",
    "\n",
    "    n = tf.cast(tf.shape(Kernel_YY)[0], tf.float32)\n",
    "    HKf = HK / (n - 1)\n",
    "    HLf = HL / (n - 1)\n",
    "\n",
    "    # biased estimate\n",
    "    hsic = tf.trace(tf.matmul(HKf, HLf))\n",
    "    return hsic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6156db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_time_MMD(data_first, data_second, data_third, data_fourth, sigma,\n",
    "    data_fifth=None, data_sixth=None):\n",
    "\n",
    "    # kernel width\n",
    "    gamma = 1 / (2 * sigma**2)\n",
    "\n",
    "    # handles X and S first\n",
    "    XX_1 = tf.matmul(data_first, data_first, transpose_b=True)\n",
    "    XX_2 = tf.matmul(data_third, data_third, transpose_b=True)\n",
    "\n",
    "    YY_1 = tf.matmul(data_second, data_second, transpose_b=True)\n",
    "    YY_2 = tf.matmul(data_fourth, data_fourth, transpose_b=True)\n",
    "\n",
    "    X_12 = tf.matmul(data_first, data_third, transpose_b=True)\n",
    "    Y_12 = tf.matmul(data_second, data_fourth, transpose_b=True)\n",
    "\n",
    "    X_sqnorms_1 = tf.diag_part(XX_1)\n",
    "    X_sqnorms_2 = tf.diag_part(XX_2)\n",
    "    Y_sqnorms_1 = tf.diag_part(YY_1)\n",
    "    Y_sqnorms_2 = tf.diag_part(YY_2)\n",
    "\n",
    "    r = lambda x: tf.expand_dims(x, 0)\n",
    "    c = lambda x: tf.expand_dims(x, 1)\n",
    "\n",
    "    # use the second binomial formula\n",
    "    Kernel_XX_1 = tf.exp(-gamma * (-2 * XX_1 + c(X_sqnorms_1) + r(X_sqnorms_1)))\n",
    "    Kernel_XX_2 = tf.exp(-gamma * (-2 * XX_2 + c(X_sqnorms_2) + r(X_sqnorms_2)))\n",
    "\n",
    "    Kernel_YY_1 = tf.exp(-gamma * (-2 * YY_1 + c(Y_sqnorms_1) + r(Y_sqnorms_1)))\n",
    "    Kernel_YY_2 = tf.exp(-gamma * (-2 * YY_2 + c(Y_sqnorms_2) + r(Y_sqnorms_2)))\n",
    "\n",
    "    Kernel_X_12 = tf.exp(-gamma * (-2 * X_12 + c(X_sqnorms_1) + r(X_sqnorms_2)))\n",
    "    Kernel_Y_12 = tf.exp(-gamma * (-2 * Y_12 + c(Y_sqnorms_1) + r(Y_sqnorms_2)))\n",
    "\n",
    "    # then handles the conditioning variable, Y\n",
    "    if data_fifth==None:\n",
    "        # use product kernels, a Hadamard product between the original kernel matrices for each variable\n",
    "        Kernel_1 = tf.multiply(Kernel_XX_1,Kernel_YY_1)\n",
    "        Kernel_2 = tf.multiply(Kernel_XX_2,Kernel_YY_2)\n",
    "        Kernel_12 = tf.multiply(Kernel_X_12,Kernel_Y_12)\n",
    "\n",
    "    else:\n",
    "        # use product kernels, a Hadamard product between the original kernel matrices for each variable\n",
    "        ZZ_1 = tf.matmul(data_fifth, data_fifth, transpose_b=True)\n",
    "        ZZ_2 = tf.matmul(data_sixth, data_sixth, transpose_b=True)\n",
    "        Z_12 = tf.matmul(data_fifth, data_sixth, transpose_b=True)\n",
    "\n",
    "        Z_sqnorms_1 = tf.diag_part(ZZ_1)\n",
    "        Z_sqnorms_2 = tf.diag_part(ZZ_2)\n",
    "\n",
    "        Kernel_ZZ_1 = tf.exp(-gamma * (-2 * ZZ_1 + c(Z_sqnorms_1) + r(Z_sqnorms_1)))\n",
    "        Kernel_ZZ_2 = tf.exp(-gamma * (-2 * ZZ_2 + c(Z_sqnorms_2) + r(Z_sqnorms_2)))\n",
    "        Kernel_Z_12 = tf.exp(-gamma * (-2 * Z_12 + c(Z_sqnorms_1) + r(Z_sqnorms_2)))\n",
    "\n",
    "        Kernel_1 = tf.multiply(Kernel_XX_1,Kernel_YY_1)\n",
    "        Kernel_1 = tf.multiply(Kernel_1,Kernel_ZZ_1)\n",
    "\n",
    "        Kernel_2 = tf.multiply(Kernel_XX_2,Kernel_YY_2)\n",
    "        Kernel_2 = tf.multiply(Kernel_2,Kernel_ZZ_2)\n",
    "\n",
    "        Kernel_12 = tf.multiply(Kernel_X_12,Kernel_Y_12)\n",
    "        Kernel_12 = tf.multiply(Kernel_12,Kernel_Z_12)\n",
    "\n",
    "    m = tf.cast(tf.shape(XX_1)[0],tf.float32)\n",
    "    n = tf.cast(tf.shape(XX_2)[0],tf.float32)\n",
    "\n",
    "    mmd2 = (tf.reduce_sum(Kernel_1) / (m * m)\n",
    "          + tf.reduce_sum(Kernel_2) / (n * n)\n",
    "          - 2 * tf.reduce_sum(Kernel_12) / (m * n))\n",
    "    return 4.0*mmd2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d9caed97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_marginal_data(*arrays, random_seed=523423, model_config):\n",
    "    # X is conditional independence of S given Y\n",
    "    # X,S,Y; permute the S according to the Y\n",
    "\n",
    "    np.random.seed(random_seed)\n",
    "    # permute all of them once\n",
    "    n_obs = len(arrays[0])\n",
    "    rperm = np.random.permutation(n_obs)\n",
    "    res = []\n",
    "    for arr in arrays:\n",
    "        res.append(arr[rperm,])\n",
    "\n",
    "    # now, permute according to the conditional independency\n",
    "    if model_config['equalized_odds']:\n",
    "        # equalized odds\n",
    "        df = pd.DataFrame(res[1])\n",
    "        df = df.groupby(res[2].flatten(), group_keys=False).transform(np.random.permutation)\n",
    "        res[1] = df.as_matrix()\n",
    "    else:\n",
    "        # equality of opportunity\n",
    "        rperm = np.random.permutation(n_obs)\n",
    "        res[1] = res[1][rperm,]\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45995444",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Performance Metric ######\n",
    "\n",
    "\n",
    "def compute_accuracy_multi_pvalue(Y, predictions, Xcontrol):\n",
    "    Xcontrol = [np.argmax(x) for x in Xcontrol]\n",
    "    correct = np.sum(Y == predictions)\n",
    "    acc = correct * 1. / Y.shape[0]\n",
    "    acc_sensitive = np.zeros(np.unique(Xcontrol).shape[0])\n",
    "    ii = 0\n",
    "    for v in np.unique(Xcontrol):\n",
    "        idx_ = Xcontrol == v\n",
    "        acc_sensitive[ii] = np.sum(Y[idx_] == predictions[idx_,]) / (np.sum(idx_) * 1.)\n",
    "        ii = ii + 1\n",
    "    return acc, acc_sensitive  # , pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "338d22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy_pvalue(Y, predictions, Xcontrol):\n",
    "    correct = np.sum(Y == predictions)\n",
    "    acc = correct * 1. / Y.shape[0]\n",
    "    acc_sensitive = np.zeros(np.unique(Xcontrol).shape[0])\n",
    "    ii = 0\n",
    "    for v in np.unique(Xcontrol):\n",
    "        idx_ = Xcontrol == v\n",
    "        acc_sensitive[ii] = np.sum(Y[idx_] == predictions[idx_,]) / (np.sum(idx_) * 1.)\n",
    "        ii = ii + 1\n",
    "    return acc, acc_sensitive  # , pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee893db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_multi_fpr_fnr(Y, predictions, Xcontrol):\n",
    "    Xcontrol = [np.argmax(x) for x in Xcontrol]\n",
    "    fp = np.sum(np.logical_and(Y == 0.0, predictions == +1.0))  # something which is -ve but is misclassified as +ve\n",
    "    fn = np.sum(np.logical_and(Y == +1.0, predictions == 0.0))  # something which is +ve but is misclassified as -ve\n",
    "    tp = np.sum(\n",
    "        np.logical_and(Y == +1.0, predictions == +1.0))  # something which is +ve AND is correctly classified as +ve\n",
    "    tn = np.sum(\n",
    "        np.logical_and(Y == 0.0, predictions == 0.0))  # something which is -ve AND is correctly classified as -ve\n",
    "    fpr_all = np.float(fp) / np.float(fp + tn)\n",
    "    fnr_all = np.float(fn) / np.float(fn + tp)\n",
    "    tpr_all = np.float(tp) / np.float(tp + fn)\n",
    "    tnr_all = np.float(tn) / np.float(tn + fp)\n",
    "\n",
    "    fpr_fnr_tpr_sensitive = np.zeros((4, np.unique(Xcontrol).shape[0]))  # ~~~ I changed this from 3 so add tnr\n",
    "    ii = 0\n",
    "    for v in np.unique(Xcontrol):\n",
    "        idx_ = Xcontrol == v\n",
    "        fp = np.sum(np.logical_and(Y[idx_] == 0.0,\n",
    "                                   predictions[idx_] == +1.0))  # something which is -ve but is misclassified as +ve\n",
    "        fn = np.sum(np.logical_and(Y[idx_] == +1.0,\n",
    "                                   predictions[idx_] == 0.0))  # something which is +ve but is misclassified as -ve\n",
    "        tp = np.sum(np.logical_and(Y[idx_] == +1.0, predictions[\n",
    "            idx_] == +1.0))  # something which is +ve AND is correctly classified as +ve\n",
    "        tn = np.sum(np.logical_and(Y[idx_] == 0.0, predictions[\n",
    "            idx_] == 0.0))  # something which is -ve AND is correctly classified as -ve\n",
    "        fpr = np.float(fp) / np.float(fp + tn)\n",
    "        fnr = np.float(fn) / np.float(fn + tp)\n",
    "        tpr = np.float(tp) / np.float(tp + fn)\n",
    "        tnr = np.float(tn) / np.float(tn + fp)\n",
    "        fpr_fnr_tpr_sensitive[0, ii] = fpr\n",
    "        fpr_fnr_tpr_sensitive[1, ii] = fnr\n",
    "        fpr_fnr_tpr_sensitive[2, ii] = tpr\n",
    "        fpr_fnr_tpr_sensitive[3, ii] = tnr\n",
    "        ii = ii + 1\n",
    "    return fpr_all, fnr_all, fpr_fnr_tpr_sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da9f4a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_fpr_fnr(Y, predictions, Xcontrol):\n",
    "    fp = np.sum(np.logical_and(Y == 0.0, predictions == +1.0))  # something which is -ve but is misclassified as +ve\n",
    "    fn = np.sum(np.logical_and(Y == +1.0, predictions == 0.0))  # something which is +ve but is misclassified as -ve\n",
    "    tp = np.sum(\n",
    "        np.logical_and(Y == +1.0, predictions == +1.0))  # something which is +ve AND is correctly classified as +ve\n",
    "    tn = np.sum(\n",
    "        np.logical_and(Y == 0.0, predictions == 0.0))  # something which is -ve AND is correctly classified as -ve\n",
    "    fpr_all = np.float(fp) / np.float(fp + tn)\n",
    "    fnr_all = np.float(fn) / np.float(fn + tp)\n",
    "    tpr_all = np.float(tp) / np.float(tp + fn)\n",
    "    tnr_all = np.float(tn) / np.float(tn + fp)\n",
    "\n",
    "    fpr_fnr_tpr_sensitive = np.zeros((4, np.unique(Xcontrol).shape[0]))\n",
    "    ii = 0\n",
    "    for v in np.unique(Xcontrol):\n",
    "        idx_ = Xcontrol == v\n",
    "        fp = np.sum(np.logical_and(Y[idx_] == 0.0,\n",
    "                                   predictions[idx_] == +1.0))  # something which is -ve but is misclassified as +ve\n",
    "        fn = np.sum(np.logical_and(Y[idx_] == +1.0,\n",
    "                                   predictions[idx_] == 0.0))  # something which is +ve but is misclassified as -ve\n",
    "        tp = np.sum(np.logical_and(Y[idx_] == +1.0, predictions[\n",
    "            idx_] == +1.0))  # something which is +ve AND is correctly classified as +ve\n",
    "        tn = np.sum(np.logical_and(Y[idx_] == 0.0, predictions[\n",
    "            idx_] == 0.0))  # something which is -ve AND is correctly classified as -ve\n",
    "        fpr = np.float(fp) / np.float(fp + tn)\n",
    "        fnr = np.float(fn) / np.float(fn + tp)\n",
    "        tpr = np.float(tp) / np.float(tp + fn)\n",
    "        tnr = np.float(tn) / np.float(tn + fp)\n",
    "        fpr_fnr_tpr_sensitive[0, ii] = fpr\n",
    "        fpr_fnr_tpr_sensitive[1, ii] = fnr\n",
    "        fpr_fnr_tpr_sensitive[2, ii] = tpr\n",
    "        fpr_fnr_tpr_sensitive[3, ii] = tnr\n",
    "        ii = ii + 1\n",
    "    return fpr_all, fnr_all, fpr_fnr_tpr_sensitive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "83e3f633",
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "class Model:\n",
    "    def __init__(self, features_size, protected_size, target_size, features_names, rff_map, rff_map_sens, to_deploy,\n",
    "                 code_size,\n",
    "                 encoder_hidden_sizes, decoder_hidden_sizes,\n",
    "                 predictor_hidden_sizes,\n",
    "                 hsic_cost_weight, pred_cost_weight, dec_cost_weight, rff_samples, equalized_odds, device):\n",
    "        if not to_deploy:\n",
    "            self.init_network(features_size, protected_size, target_size, features_names, code_size,\n",
    "                              encoder_hidden_sizes, decoder_hidden_sizes,\n",
    "                              predictor_hidden_sizes, to_deploy, device)\n",
    "            self.init_training(hsic_cost_weight, pred_cost_weight, dec_cost_weight, rff_map, rff_map_sens,\n",
    "                               equalized_odds)\n",
    "            self.init_logging(hsic_cost_weight, pred_cost_weight, dec_cost_weight)\n",
    "        else:\n",
    "            self.init_network(features_size, protected_size, target_size, features_names, code_size,\n",
    "                              encoder_hidden_sizes, decoder_hidden_sizes,\n",
    "                              predictor_hidden_sizes, to_deploy, device)\n",
    "\n",
    "    def init_network(self, features_size, protected_size, target_size, features,\n",
    "                     code_size, encoder_hidden_sizes, decoder_hidden_sizes,\n",
    "                     predictor_hidden_sizes, deploy, device):\n",
    "\n",
    "        self.x = tf.placeholder(tf.float32, [None, features_size], name=\"x\")\n",
    "        self.s = tf.placeholder(tf.float32, [None, protected_size], name=\"s\")\n",
    "        self.y = tf.placeholder(tf.float32, [None, target_size], name=\"y\")\n",
    "        self.x_marg = tf.placeholder(tf.float32, [None, features_size], name=\"x_marg\")\n",
    "        self.s_marg = tf.placeholder(tf.float32, [None, protected_size], name=\"s_marg\")\n",
    "        self.y_marg = tf.placeholder(tf.float32, [None, target_size], name=\"y_marg\")\n",
    "        self.keep_prob = tf.placeholder(tf.float32)\n",
    "\n",
    "        with tf.device(device):\n",
    "            with tf.variable_scope('encoder'):\n",
    "                prev_layer = self.x\n",
    "                for size in encoder_hidden_sizes:\n",
    "                    prev_layer = dense_bn_relu(prev_layer, size, deploy)\n",
    "                tmp = tf.layers.dense(\n",
    "                    prev_layer, code_size, activation=None,\n",
    "                    kernel_initializer=tf.uniform_unit_scaling_initializer(\n",
    "                        seed=888))\n",
    "                self.encoded = tf.nn.dropout(tmp, keep_prob=self.keep_prob, seed=888)\n",
    "\n",
    "            with tf.variable_scope('decoder'):\n",
    "                prev_layer = self.encoded\n",
    "                for size in decoder_hidden_sizes:\n",
    "                    prev_layer = dense_bn_relu(prev_layer, size, deploy)\n",
    "                # take into account the structure of our features\n",
    "                keys_f = features.keys()\n",
    "                ii = 0\n",
    "                for key_f in keys_f:\n",
    "                    if sum(features[key_f]) > 0 and sum(features[key_f]) == 1:\n",
    "                        inc_unit = tf.layers.dense(\n",
    "                            prev_layer, sum(features[key_f]), activation=None,\n",
    "                            kernel_initializer=tf.uniform_unit_scaling_initializer(seed=888))\n",
    "                        if ii == 0:\n",
    "                            self.decoded = inc_unit\n",
    "                        else:\n",
    "                            self.decoded = tf.concat([self.decoded, inc_unit], axis=1)\n",
    "                    elif sum(features[key_f]) > 1:\n",
    "                        inc_unit = tf.layers.dense(\n",
    "                            prev_layer, sum(features[key_f]), activation=tf.nn.softmax,\n",
    "                            kernel_initializer=tf.uniform_unit_scaling_initializer(seed=888))\n",
    "                        if ii == 0:\n",
    "                            if deploy:  # use one hot encoding at the deployment\n",
    "                                self.decoded = tf.one_hot(tf.argmax(inc_unit, dimension=1), depth=sum(features[key_f]))\n",
    "                            else:  # use soft outputs for learning\n",
    "                                self.decoded = inc_unit\n",
    "                        else:\n",
    "                            if deploy:  # use one hot encoding at the deployment\n",
    "                                self.decoded = tf.concat([self.decoded, tf.one_hot(tf.argmax(inc_unit, dimension=1),\n",
    "                                                                                   depth=sum(features[key_f]))], axis=1)\n",
    "                            else:  # use soft outputs for learning\n",
    "                                self.decoded = tf.concat([self.decoded, inc_unit],\n",
    "                                                         axis=1)\n",
    "                    ii += 1\n",
    "\n",
    "            with tf.variable_scope('encoder', reuse=True):\n",
    "                prev_layer = self.x_marg\n",
    "                for size in encoder_hidden_sizes:\n",
    "                    prev_layer = dense_bn_relu(prev_layer, size, deploy)\n",
    "                tmp = tf.layers.dense(\n",
    "                    prev_layer, code_size, activation=None,\n",
    "                    kernel_initializer=tf.uniform_unit_scaling_initializer(\n",
    "                        seed=888))\n",
    "                self.encoded_marginal = tf.nn.dropout(tmp, keep_prob=self.keep_prob, seed=888)\n",
    "\n",
    "            with tf.variable_scope('decoder', reuse=True):\n",
    "                prev_layer = self.encoded_marginal\n",
    "                for size in decoder_hidden_sizes:\n",
    "                    prev_layer = dense_bn_relu(prev_layer, size, deploy)\n",
    "                # take into account the structure of our features\n",
    "                keys_f = features.keys()\n",
    "                ii = 0\n",
    "                for key_f in keys_f:\n",
    "                    if sum(features[key_f]) > 0 and sum(features[key_f]) == 1:\n",
    "                        inc_unit = tf.layers.dense(\n",
    "                            prev_layer, sum(features[key_f]), activation=None,\n",
    "                            kernel_initializer=tf.uniform_unit_scaling_initializer(seed=888))\n",
    "                        if ii == 0:\n",
    "                            self.decoded_marginal = inc_unit\n",
    "                        else:\n",
    "                            self.decoded_marginal = tf.concat([self.decoded_marginal, inc_unit], axis=1)\n",
    "                    elif sum(features[key_f]) > 1:\n",
    "                        inc_unit = tf.layers.dense(\n",
    "                            prev_layer, sum(features[key_f]), activation=tf.nn.softmax,\n",
    "                            kernel_initializer=tf.uniform_unit_scaling_initializer(seed=888))\n",
    "                        if ii == 0:\n",
    "                            if deploy:  # use one hot encoding at the deployment\n",
    "                                self.decoded_marginal = tf.one_hot(tf.argmax(inc_unit, dimension=1),\n",
    "                                                                   depth=sum(features[key_f]))\n",
    "                            else:  # use soft outputs for learning\n",
    "                                self.decoded_marginal = inc_unit\n",
    "                        else:\n",
    "                            if deploy:  # use one hot encoding at the deployment\n",
    "                                self.decoded_marginal = tf.concat([self.decoded_marginal,\n",
    "                                                                   tf.one_hot(tf.argmax(inc_unit, dimension=1),\n",
    "                                                                              depth=sum(features[key_f]))], axis=1)\n",
    "                            else:  # use soft outputs for learning\n",
    "                                self.decoded_marginal = tf.concat([self.decoded_marginal, inc_unit],\n",
    "                                                                  axis=1)\n",
    "                    ii += 1\n",
    "\n",
    "            with tf.variable_scope('predictor'):\n",
    "                prev_layer = self.decoded\n",
    "                for size in predictor_hidden_sizes:\n",
    "                    prev_layer = dense_bn_relu(prev_layer, size, deploy)\n",
    "                self.y_logit = tf.layers.dense(\n",
    "                    prev_layer, target_size, activation=None,\n",
    "                    kernel_initializer=tf.uniform_unit_scaling_initializer(seed=888))\n",
    "                self.y_prob = tf.nn.sigmoid(self.y_logit)\n",
    "                self.y_pred = tf.cast(\n",
    "                    tf.greater(self.y_prob, 0.5), tf.int32)\n",
    "\n",
    "    def init_training(self, hsic_cost_weight, pred_cost_weight, dec_cost_weight,\n",
    "                      rff_map, rff_map_sens, equalized_odds):\n",
    "\n",
    "        self.y_cost = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            logits=self.y_logit, labels=tf.cast(self.y, tf.float32)))\n",
    "\n",
    "        # compute MMD and decoder loss in the feature space\n",
    "        # via random Fourier features machinery\n",
    "        x_map = rff_map.map(self.x)\n",
    "        x_marginal_map = rff_map.map(self.x_marg)\n",
    "        decoded_map = rff_map.map(self.decoded)\n",
    "        decoded_marginal_map = rff_map.map(self.decoded_marginal)\n",
    "        sens_map = self.s\n",
    "        sens_marginal_map = self.s_marg\n",
    "\n",
    "        self.decoder_loss = tf.reduce_mean(\n",
    "            tf.nn.l2_loss(self.x - self.decoded))\n",
    "\n",
    "        if equalized_odds:\n",
    "            # EQUALIZED ODDS\n",
    "            print(\"Equalized Odds Criterion\")\n",
    "            self.cycling_cost = -quadratic_time_MMD(x_map - decoded_map,\n",
    "                                                    sens_map, x_marginal_map - decoded_marginal_map,\n",
    "                                                    sens_marginal_map, 0.2, self.y, self.y_marg)\n",
    "        else:\n",
    "            # EQUALITY of OPPORTUNITY\n",
    "            print(\"Equal Opportunity Criterion\")\n",
    "            mask = tf.equal(tf.squeeze(self.y),1)\n",
    "            x_map_pos = tf.gather_nd(x_map, tf.where(mask))\n",
    "            x_marginal_map_pos = tf.gather_nd(x_marginal_map, tf.where(mask))\n",
    "            decoded_map_pos = tf.gather_nd(decoded_map, tf.where(mask))\n",
    "            decoded_marginal_map_pos = tf.gather_nd(decoded_marginal_map, tf.where(mask))\n",
    "            sens_map_pos = tf.gather_nd(sens_map, tf.where(mask))\n",
    "            sens_marginal_map_pos = tf.gather_nd(sens_marginal_map, tf.where(mask))\n",
    "\n",
    "            self.cycling_cost = -(quadratic_time_HSIC(x_map_pos - decoded_map_pos, sens_map_pos, tf.sqrt(tf.constant([0.5])), tf.constant([1.])))\n",
    "\n",
    "            self.hsic_cost = quadratic_time_HSIC(decoded_map_pos, sens_map_pos, tf.sqrt(tf.constant([0.5])), tf.constant([1.]))\n",
    "\n",
    "        self.pred_loss = (hsic_cost_weight * self.cycling_cost +\n",
    "                          (hsic_cost_weight * self.hsic_cost) +\n",
    "                          dec_cost_weight * self.decoder_loss +\n",
    "                          pred_cost_weight * self.y_cost)\n",
    "\n",
    "        pred_vars = (\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'encoder') +\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'decoder') +\n",
    "                tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, 'predictor')\n",
    "        )\n",
    "        self.train_pred = tf.train.AdamOptimizer().minimize(\n",
    "            self.pred_loss, var_list=pred_vars)\n",
    "\n",
    "    def init_logging(self, hsic_cost_weight, pred_cost_weight, dec_cost_weight):\n",
    "        # which variables to log\n",
    "        tf.summary.scalar(\"decoder_loss\", self.decoder_loss)\n",
    "        tf.summary.scalar(\"decoder_loss_with_weight\", dec_cost_weight * self.decoder_loss)\n",
    "        tf.summary.scalar(\"pred_loss\", self.pred_loss)\n",
    "        tf.summary.scalar(\"y_cost\", self.y_cost)\n",
    "        tf.summary.scalar(\"y_cost_with_weight\", pred_cost_weight * self.y_cost)\n",
    "        tf.summary.scalar(\"cycling_cost\", self.cycling_cost)\n",
    "        tf.summary.scalar(\"cycling_cost_with_weight\", hsic_cost_weight * self.cycling_cost)\n",
    "        tf.summary.scalar(\"hsic_cost\", self.hsic_cost)\n",
    "        tf.summary.scalar(\"hsic_cost_with_weight\", hsic_cost_weight * self.hsic_cost)\n",
    "\n",
    "        self.summary_op = tf.summary.merge_all()\n",
    "\n",
    "        self.global_step = tf.Variable(0, name='global_step',\n",
    "                                       trainable=False, dtype=tf.int32)\n",
    "        self.inc_step = tf.assign(self.global_step, self.global_step + 1)\n",
    "\n",
    "        self.global_iteration = tf.Variable(0, name='global_iteration',\n",
    "                                            trainable=False, dtype=tf.int32)\n",
    "        self.inc_iteration = tf.assign(self.global_iteration,\n",
    "                                       self.global_iteration + 1)\n",
    "\n",
    "    def fit(self, train_data, train_data_marginal, valid_data, valid_data_marginal, SEED_NUM, logs_dir, verbose,\n",
    "            tf_config,\n",
    "            n_iterations, batch_size, model_save_iterations, report_iterations,\n",
    "            pred_steps_per_iteration,\n",
    "            init_random_seed):\n",
    "\n",
    "        X_train, s_train, y_train = train_data\n",
    "        X_valid, s_valid, y_valid = valid_data\n",
    "\n",
    "        X_train_marginal, s_train_marginal, y_train_marginal = train_data_marginal\n",
    "        X_valid_marginal, s_valid_marginal, y_valid_marginal = valid_data_marginal\n",
    "\n",
    "        model_saver = tf.train.Saver(max_to_keep=None)\n",
    "        models_dir = logs_dir + '/models_{}/'.format(SEED_NUM)\n",
    "        last_exists = True\n",
    "        last_path = models_dir + 'last.session'\n",
    "        if not os.path.exists(models_dir):\n",
    "            os.makedirs(models_dir)\n",
    "            last_exists = False\n",
    "\n",
    "        with tf.Session(config=tf_config) as sess:\n",
    "            np.random.seed(init_random_seed)\n",
    "            tf.set_random_seed(0)\n",
    "            if last_exists:\n",
    "                model_saver.restore(sess, last_path)\n",
    "            else:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            train_writer = tf.summary.FileWriter(logs_dir + '/tb/train',\n",
    "                                                 sess.graph)\n",
    "            valid_writer = tf.summary.FileWriter(logs_dir + '/tb/valid')\n",
    "\n",
    "            total_batches = int(X_train.shape[0] // batch_size)\n",
    "\n",
    "            def _train_feed_dict(step):\n",
    "                begin = (step % total_batches) * batch_size\n",
    "                end = (step % total_batches + 1) * batch_size\n",
    "                return {\n",
    "                    self.x: X_train[begin:end],\n",
    "                    self.s: s_train[begin:end],\n",
    "                    self.y: y_train[begin:end],\n",
    "                    self.x_marg: X_train_marginal[begin:end],\n",
    "                    self.s_marg: s_train_marginal[begin:end],\n",
    "                    self.y_marg: y_train_marginal[begin:end],\n",
    "                    self.keep_prob: 1.0\n",
    "                }\n",
    "\n",
    "            for _ in range(n_iterations):\n",
    "                iteration = sess.run(self.inc_iteration)\n",
    "\n",
    "                for _ in range(pred_steps_per_iteration):\n",
    "                    step = sess.run(self.inc_step)\n",
    "                    s, _ = sess.run([self.summary_op, self.train_pred],\n",
    "                                    feed_dict=_train_feed_dict(step))\n",
    "                    train_writer.add_summary(s, step)\n",
    "\n",
    "                if iteration % report_iterations == 0:\n",
    "                    s = sess.run(\n",
    "                        self.summary_op,\n",
    "                        feed_dict={self.x: X_valid,\n",
    "                                   self.s: s_valid,\n",
    "                                   self.y: y_valid,\n",
    "                                   self.x_marg: X_valid_marginal,\n",
    "                                   self.s_marg: s_valid_marginal,\n",
    "                                   self.y_marg: y_valid_marginal,\n",
    "                                   self.keep_prob: 1.0})\n",
    "                    valid_writer.add_summary(s, step)\n",
    "\n",
    "                if iteration % model_save_iterations == 0:\n",
    "                    path = models_dir + 'iteration_{}.session'.format(iteration)\n",
    "                    model_saver.save(sess, path)\n",
    "\n",
    "                if verbose and iteration % report_iterations == 0:\n",
    "                    print(\"Finished iteration {}\".format(iteration))\n",
    "\n",
    "            model_saver.save(sess, last_path)\n",
    "\n",
    "    def predict(self, model, features, logs_dir_f, tf_config, iteration, SEED_NUM):\n",
    "        model_saver = tf.train.Saver()\n",
    "        with tf.Session(config=tf_config) as sess:\n",
    "            path = '{}/models_{}/iteration_{}.session'.format(logs_dir_f, SEED_NUM, iteration)\n",
    "            model_saver.restore(sess, path)\n",
    "            y_pred = model.y_pred.eval({model.x: features, model.keep_prob: 1.0})\n",
    "            y_prob = model.y_prob.eval({model.x: features, model.keep_prob: 1.0})\n",
    "            decoded = model.decoded.eval({model.x: features, model.keep_prob: 1.0})\n",
    "        return y_pred, y_prob, decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e68a6914",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(data_train, data_train_marginal, data_valid, data_valid_marginal, x_size, s_size, y_size, med_sq_dist,\n",
    "          features, logs_dir_f, SEED_NUM, model_config, fit_config, device=\"cpu\"):\n",
    "    kernel_mapper = tf.contrib.kernel_methods.RandomFourierFeatureMapper(input_dim=x_size,\n",
    "                                                                         output_dim=model_config['rff_samples'],\n",
    "                                                                         stddev=med_sq_dist, seed=888,\n",
    "                                                                         name='kernel_mapper')\n",
    "    kernel_mapper_sens = tf.contrib.kernel_methods.RandomFourierFeatureMapper(input_dim=s_size,\n",
    "                                                                              output_dim=model_config['rff_samples'],\n",
    "                                                                              stddev=1.0, seed=888,\n",
    "                                                                              name='kernel_mapper_sens')\n",
    "\n",
    "    if device == \"cpu\":\n",
    "        device = \"/cpu:0\"\n",
    "    else:\n",
    "        device = \"/gpu:0\"\n",
    "\n",
    "    tf.reset_default_graph()\n",
    "    with tf.Graph().as_default():\n",
    "        model = Model(features_size=x_size, protected_size=s_size, target_size=y_size, features_names=features,\n",
    "                      rff_map=kernel_mapper, rff_map_sens=kernel_mapper_sens, to_deploy=False, device=device,\n",
    "                      **model_config)\n",
    "\n",
    "        tf_config = tf.ConfigProto()\n",
    "        tf_config.gpu_options.allow_growth = True\n",
    "\n",
    "        model.fit(data_train, data_train_marginal, data_valid, data_valid_marginal, SEED_NUM,\n",
    "                  tf_config=tf_config, verbose=True, logs_dir=logs_dir_f,\n",
    "                  **fit_config)\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ba0296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(data_train, data_valid, data_test, features, logs_dir_f, SEED_NUM, model_config, device=\"cpu\"):\n",
    "    # Computational graphs are associated with Sessions. \n",
    "    # We should \"clear out\" the state of the Session so we don't have multiple placeholder objects floating around \n",
    "    # as we call save and restore()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    if device == \"cpu\":\n",
    "        device = \"/cpu:0\"\n",
    "    else:\n",
    "        device = \"/gpu:0\"\n",
    "\n",
    "    tf_config = tf.ConfigProto()\n",
    "    tf_config.gpu_options.allow_growth = True\n",
    "    kernel_mapper = None\n",
    "    kernel_mapper_sens = None\n",
    "    model = Model(features_size=data_train[0].shape[1], protected_size=data_train[1].shape[1],\n",
    "                  target_size=data_train[2].shape[1], features_names=features, rff_map=kernel_mapper,\n",
    "                  rff_map_sens=kernel_mapper_sens, to_deploy=True, device=device,\n",
    "                  **model_config)\n",
    "\n",
    "    all_iterations = []\n",
    "    for file in os.listdir(logs_dir_f + '/models_{}/'.format(SEED_NUM)):\n",
    "        if fnmatch.fnmatch(file, 'iteration_*.session.meta'):\n",
    "            iteration = file[len('iteration_'): -len('.session.meta')]\n",
    "            all_iterations.append(int(iteration))\n",
    "    all_iterations = sorted(all_iterations)\n",
    "\n",
    "    X_train, s_train, y_train = data_train\n",
    "    X_valid, s_valid, y_valid = data_valid\n",
    "    X_test, s_test, y_test = data_test\n",
    "    tpr_diff = []\n",
    "    fpr_dif = []\n",
    "    acc_ = []\n",
    "\n",
    "    # perform classification here with X and Xtilde\n",
    "    reg_array = [10 ** i for i in range(7)]\n",
    "    n_splits = 3\n",
    "    cv = cross_validation.StratifiedKFold(n_splits=n_splits, random_state=888, shuffle=True)\n",
    "    # with Xtilde\n",
    "    print(\"with Xtilde for all iterations\")\n",
    "    decoded_train = None\n",
    "    decoded_test = None\n",
    "    for iteration in all_iterations[-1:]:\n",
    "        y_pred_train, y_prob_train, decoded_train = model.predict(model, X_train, logs_dir_f, tf_config, iteration,\n",
    "                                                                  SEED_NUM)\n",
    "        y_pred_valid, y_prob_valid, decoded_valid = model.predict(model, X_valid, logs_dir_f, tf_config, iteration,\n",
    "                                                                  SEED_NUM)\n",
    "        y_pred_test, y_prob_test, decoded_test = model.predict(model, X_test, logs_dir_f, tf_config, iteration,\n",
    "                                                               SEED_NUM)\n",
    "\n",
    "        cv_scores = np.zeros((len(reg_array), n_splits))\n",
    "        for i, reg_const in enumerate(reg_array):\n",
    "            cv_scores[i] = cross_validation.cross_val_score(\n",
    "                svm.LinearSVC(C=reg_const, dual=False, tol=1e-6, random_state=888), decoded_train, y_train.flatten(),\n",
    "                cv=cv)\n",
    "        cv_mean = np.mean(cv_scores, axis=1)\n",
    "        reg_best = reg_array[np.argmax(cv_mean)]\n",
    "        print(\"Regularization \", reg_best)\n",
    "        clf = svm.LinearSVC(C=reg_best, dual=False, tol=1e-6, random_state=888)\n",
    "        clf.fit(decoded_train, y_train.flatten())\n",
    "\n",
    "        predictions = clf.predict(decoded_test)\n",
    "        # performance measurement\n",
    "        acc, acc_sensitive = compute_accuracy_pvalue(y_test.flatten(), predictions,\n",
    "                                                     s_test.flatten())\n",
    "        print('SVM Accuracy: %.2f%%' % (acc * 100.))\n",
    "        print(\"per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "        acc_sensitive[0] * 100., acc_sensitive[1] * 100., (acc_sensitive[0] - acc_sensitive[1]) * 100.))\n",
    "        fpr, fnr, fpr_fnr_tpr_sensitive = compute_fpr_fnr(y_test.flatten(), predictions,\n",
    "                                                          s_test.flatten())\n",
    "        print('SVM FPR and FNR: %.2f, %.2f' % (fpr * 100., fnr * 100.))\n",
    "        print(\"TPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "        fpr_fnr_tpr_sensitive[2, 0] * 100., fpr_fnr_tpr_sensitive[2, 1] * 100.,\n",
    "        (fpr_fnr_tpr_sensitive[2, 0] - fpr_fnr_tpr_sensitive[2, 1]) * 100.))\n",
    "        print(\"FPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "        fpr_fnr_tpr_sensitive[0, 0] * 100., fpr_fnr_tpr_sensitive[0, 1] * 100.,\n",
    "        (fpr_fnr_tpr_sensitive[0, 0] - fpr_fnr_tpr_sensitive[0, 1]) * 100.))\n",
    "        print(\"FNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "        fpr_fnr_tpr_sensitive[1, 0] * 100., fpr_fnr_tpr_sensitive[1, 1] * 100.,\n",
    "        (fpr_fnr_tpr_sensitive[1, 0] - fpr_fnr_tpr_sensitive[1, 1]) * 100.))\n",
    "        print(\"TNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "        fpr_fnr_tpr_sensitive[3, 0] * 100., fpr_fnr_tpr_sensitive[3, 1] * 100.,\n",
    "        (fpr_fnr_tpr_sensitive[3, 0] - fpr_fnr_tpr_sensitive[3, 1]) * 100.))\n",
    "        print(\"\\n\")\n",
    "        acc_.append(acc)\n",
    "        tpr_diff.append((fpr_fnr_tpr_sensitive[2, 0] - fpr_fnr_tpr_sensitive[2, 1]) * 100.)\n",
    "        fpr_dif.append((fpr_fnr_tpr_sensitive[0, 0] - fpr_fnr_tpr_sensitive[0, 1]) * 100.)\n",
    "\n",
    "        x_column_names = [\"age\",\n",
    "                          \"education-num\",\n",
    "                          \"capital-gain\",\n",
    "                          \"capital-loss\",\n",
    "                          \"hours-per-week\",\n",
    "                          \"workclass_Federal-gov\",\n",
    "                          \"workclass_Local-gov\",\n",
    "                          \"workclass_Never-worked\",\n",
    "                          \"workclass_Private\",\n",
    "                          \"workclass_Self-emp-inc\",\n",
    "                          \"workclass_Self-emp-not-inc\",\n",
    "                          \"workclass_State-gov\",\n",
    "                          \"workclass_Without-pay\",\n",
    "                          \"education_10th\",\n",
    "                          \"education_11th\",\n",
    "                          \"education_12th\",\n",
    "                          \"education_1st-4th\",\n",
    "                          \"education_5th-6th\",\n",
    "                          \"education_7th-8th\",\n",
    "                          \"education_9th\",\n",
    "                          \"education_Assoc-acdm\",\n",
    "                          \"education_Assoc-voc\",\n",
    "                          \"education_Bachelors\",\n",
    "                          \"education_Doctorate\",\n",
    "                          \"education_HS-grad\",\n",
    "                          \"education_Masters\",\n",
    "                          \"education_Preschool\",\n",
    "                          \"education_Prof-school\",\n",
    "                          \"education_Some-college\",\n",
    "                          \"marital-status_Divorced\",\n",
    "                          \"marital-status_Married-AF-spouse\",\n",
    "                          \"marital-status_Married-civ-spouse\",\n",
    "                          \"marital-status_Married-spouse-absent\",\n",
    "                          \"marital-status_Never-married\",\n",
    "                          \"marital-status_Separated\",\n",
    "                          \"marital-status_Widowed\",\n",
    "                          \"occupation_Adm-clerical\",\n",
    "                          \"occupation_Armed-Forces\",\n",
    "                          \"occupation_Craft-repair\",\n",
    "                          \"occupation_Exec-managerial\",\n",
    "                          \"occupation_Farming-fishing\",\n",
    "                          \"occupation_Handlers-cleaners\",\n",
    "                          \"occupation_Machine-op-inspct\",\n",
    "                          \"occupation_Other-service\",\n",
    "                          \"occupation_Priv-house-serv\",\n",
    "                          \"occupation_Prof-specialty\",\n",
    "                          \"occupation_Protective-serv\",\n",
    "                          \"occupation_Sales\",\n",
    "                          \"occupation_Tech-support\",\n",
    "                          \"occupation_Transport-moving\",\n",
    "                          \"relationship_Husband\",\n",
    "                          \"relationship_Not-in-family\",\n",
    "                          \"relationship_Other-relative\",\n",
    "                          \"relationship_Own-child\",\n",
    "                          \"relationship_Unmarried\",\n",
    "                          \"relationship_Wife\",\n",
    "                          # \"sex_Female\",\n",
    "                          # \"sex_Male\",\n",
    "                          \"race_Amer-Indian-Eskimo\",\n",
    "                          \"race_Asian-Pac-Islander\",\n",
    "                          \"race_Black\",\n",
    "                          \"race_Other\",\n",
    "                          \"race_White\",\n",
    "                          \"native-country_Cambodia\",\n",
    "                          \"native-country_Canada\",\n",
    "                          \"native-country_China\",\n",
    "                          \"native-country_Columbia\",\n",
    "                          \"native-country_Cuba\",\n",
    "                          \"native-country_Dominican-Republic\",\n",
    "                          \"native-country_Ecuador\",\n",
    "                          \"native-country_El-Salvador\",\n",
    "                          \"native-country_England\",\n",
    "                          \"native-country_France\",\n",
    "                          \"native-country_Germany\",\n",
    "                          \"native-country_Greece\",\n",
    "                          \"native-country_Guatemala\",\n",
    "                          \"native-country_Haiti\",\n",
    "                          \"native-country_Holand-Netherlands\",\n",
    "                          \"native-country_Honduras\",\n",
    "                          \"native-country_Hong\",\n",
    "                          \"native-country_Hungary\",\n",
    "                          \"native-country_India\",\n",
    "                          \"native-country_Iran\",\n",
    "                          \"native-country_Ireland\",\n",
    "                          \"native-country_Italy\",\n",
    "                          \"native-country_Jamaica\",\n",
    "                          \"native-country_Japan\",\n",
    "                          \"native-country_Laos\",\n",
    "                          \"native-country_Mexico\",\n",
    "                          \"native-country_Nicaragua\",\n",
    "                          \"native-country_Outlying-US(Guam-USVI-etc)\",\n",
    "                          \"native-country_Peru\",\n",
    "                          \"native-country_Philippines\",\n",
    "                          \"native-country_Poland\",\n",
    "                          \"native-country_Portugal\",\n",
    "                          \"native-country_Puerto-Rico\",\n",
    "                          \"native-country_Scotland\",\n",
    "                          \"native-country_South\",\n",
    "                          \"native-country_Taiwan\",\n",
    "                          \"native-country_Thailand\",\n",
    "                          \"native-country_Trinadad&Tobago\",\n",
    "                          \"native-country_United-States\",\n",
    "                          \"native-country_Vietnam\",\n",
    "                          \"native-country_Yugoslavia\",\n",
    "                          ]\n",
    "\n",
    "        s_column_name = [\"sensitive\"]\n",
    "        y_column_name = [\"label\"]\n",
    "\n",
    "        train_x_dataframe = pd.DataFrame(X_train)\n",
    "        train_s_dataframe = pd.DataFrame(s_train, dtype='int32')\n",
    "        train_y_dataframe = pd.DataFrame(y_train, dtype='int32')\n",
    "\n",
    "        train_x_dataframe.columns = x_column_names\n",
    "        train_s_dataframe.columns = s_column_name\n",
    "        train_y_dataframe.columns = y_column_name\n",
    "\n",
    "        train_dataframe = pd.concat([train_x_dataframe, train_s_dataframe, train_y_dataframe], axis=1)\n",
    "\n",
    "        train_x_tilde_dataframe = pd.DataFrame(decoded_train)\n",
    "        train_x_tilde_dataframe.columns = x_column_names\n",
    "        train_tilde_dataframe = pd.concat([train_x_tilde_dataframe, train_s_dataframe, train_y_dataframe], axis=1)\n",
    "\n",
    "        train_dataframe.to_csv(\"seed_{}_stylingtrain_{}.csv\".format(SEED_NUM, iteration), index=False)\n",
    "        train_tilde_dataframe.to_csv(\"seed_{}_stylingtraintilde_{}.csv\".format(SEED_NUM, iteration), index=False)\n",
    "\n",
    "        test_x_dataframe = pd.DataFrame(X_test)\n",
    "        test_s_dataframe = pd.DataFrame(s_test, dtype='int32')\n",
    "        test_y_dataframe = pd.DataFrame(y_test, dtype='int32')\n",
    "\n",
    "        test_x_dataframe.columns = x_column_names\n",
    "        test_s_dataframe.columns = s_column_name\n",
    "        test_y_dataframe.columns = y_column_name\n",
    "\n",
    "        test_dataframe = pd.concat([test_x_dataframe, test_s_dataframe, test_y_dataframe], axis=1)\n",
    "\n",
    "        test_x_tilde_dataframe = pd.DataFrame(decoded_test)\n",
    "        test_x_tilde_dataframe.columns = x_column_names\n",
    "        test_tilde_dataframe = pd.concat([test_x_tilde_dataframe, test_s_dataframe, test_y_dataframe], axis=1)\n",
    "\n",
    "        test_dataframe.to_csv(\"seed_{}_stylingtest_{}.csv\".format(SEED_NUM, iteration), index=False)\n",
    "        test_tilde_dataframe.to_csv(\"seed_{}_stylingtesttilde_{}.csv\".format(SEED_NUM, iteration), index=False)\n",
    "\n",
    "    print(np.array(acc_))\n",
    "    print(np.array(tpr_diff))\n",
    "    print(np.array(fpr_dif))\n",
    "\n",
    "    # performance measurement\n",
    "    cv_scores = np.zeros((len(reg_array), n_splits))\n",
    "    print(\"with X\")\n",
    "    for i, reg_const in enumerate(reg_array):\n",
    "        cv_scores[i] = cross_validation.cross_val_score(\n",
    "            svm.LinearSVC(C=reg_const, dual=False, tol=1e-6, random_state=888), X_train, y_train.flatten(), cv=cv)\n",
    "    print(\"CV_Scores\", cv_scores)\n",
    "    cv_mean = np.mean(cv_scores, axis=1)\n",
    "    print(\"CV Mean\", cv_mean)\n",
    "    reg_best = reg_array[np.argmax(cv_mean)]\n",
    "    clf = svm.LinearSVC(C=reg_best, dual=False, tol=1e-6, random_state=888)\n",
    "    clf.fit(X_train, y_train.flatten())\n",
    "    predictions = clf.predict(X_test)\n",
    "\n",
    "    acc, acc_sensitive = compute_accuracy_pvalue(y_test.flatten(), predictions,\n",
    "                                                 s_test.flatten())\n",
    "    print('SVM Accuracy: %.2f%%' % (acc * 100.))\n",
    "    print('Reg: %.2f' % (reg_best))\n",
    "    print(\"per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    acc_sensitive[0] * 100., acc_sensitive[1] * 100., (acc_sensitive[0] - acc_sensitive[1]) * 100.))\n",
    "    fpr, fnr, fpr_fnr_tpr_sensitive = compute_fpr_fnr(y_test.flatten(), predictions,\n",
    "                                                      s_test.flatten())\n",
    "    print('SVM FPR and FNR: %.2f, %.2f' % (fpr * 100., fnr * 100.))\n",
    "    print(\"TPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[2, 0] * 100., fpr_fnr_tpr_sensitive[2, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[2, 0] - fpr_fnr_tpr_sensitive[2, 1]) * 100.))\n",
    "    print(\"FPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[0, 0] * 100., fpr_fnr_tpr_sensitive[0, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[0, 0] - fpr_fnr_tpr_sensitive[0, 1]) * 100.))\n",
    "    print(\"FNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[1, 0] * 100., fpr_fnr_tpr_sensitive[1, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[1, 0] - fpr_fnr_tpr_sensitive[1, 1]) * 100.))\n",
    "    print(\"TNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[3, 0] * 100., fpr_fnr_tpr_sensitive[3, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[3, 0] - fpr_fnr_tpr_sensitive[3, 1]) * 100.))\n",
    "    print(\"\\n\")\n",
    "    # with Xtilde\n",
    "    cv_scores = np.zeros((len(reg_array), n_splits))\n",
    "    print(\"with Xtilde\")\n",
    "    for i, reg_const in enumerate(reg_array):\n",
    "        cv_scores[i] = cross_validation.cross_val_score(\n",
    "            svm.LinearSVC(C=reg_const, dual=False, tol=1e-6, random_state=888), decoded_train, y_train.flatten(), cv=cv)\n",
    "    print(\"CV_Scores\", cv_scores)\n",
    "    cv_mean = np.mean(cv_scores, axis=1)\n",
    "    print(\"CV Mean\", cv_mean)\n",
    "    reg_best = reg_array[np.argmax(cv_mean)]\n",
    "    clf = svm.LinearSVC(C=reg_best, dual=False, tol=1e-6, random_state=888)\n",
    "    clf.fit(decoded_train, y_train.flatten())\n",
    "    predictions = clf.predict(decoded_test)\n",
    "    # performance measurement\n",
    "    acc, acc_sensitive = compute_accuracy_pvalue(y_test.flatten(), predictions,\n",
    "                                                 s_test.flatten())\n",
    "    print('SVM Accuracy: %.2f%%' % (acc * 100.))\n",
    "    print(\"reg value: %.2f\" % (reg_best))\n",
    "    print(\"per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    acc_sensitive[0] * 100., acc_sensitive[1] * 100., (acc_sensitive[0] - acc_sensitive[1]) * 100.))\n",
    "    fpr, fnr, fpr_fnr_tpr_sensitive = compute_fpr_fnr(y_test.flatten(), predictions,\n",
    "                                                      s_test.flatten())\n",
    "    print('SVM FPR and FNR: %.2f, %.2f' % (fpr * 100., fnr * 100.))\n",
    "    print(\"TPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[2, 0] * 100., fpr_fnr_tpr_sensitive[2, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[2, 0] - fpr_fnr_tpr_sensitive[2, 1]) * 100.))\n",
    "    print(\"FPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[0, 0] * 100., fpr_fnr_tpr_sensitive[0, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[0, 0] - fpr_fnr_tpr_sensitive[0, 1]) * 100.))\n",
    "    print(\"FNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[1, 0] * 100., fpr_fnr_tpr_sensitive[1, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[1, 0] - fpr_fnr_tpr_sensitive[1, 1]) * 100.))\n",
    "    print(\"TNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[3, 0] * 100., fpr_fnr_tpr_sensitive[3, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[3, 0] - fpr_fnr_tpr_sensitive[3, 1]) * 100.))\n",
    "    print(\"\\n\")\n",
    "\n",
    "    acc, acc_sensitive = compute_accuracy_pvalue(y_test.flatten(), y_pred_test.flatten(), s_test.flatten())\n",
    "    print('Encoder Accuracy: %.2f%%' % (acc * 100.))\n",
    "    print(\"per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    acc_sensitive[0] * 100., acc_sensitive[1] * 100., (acc_sensitive[0] - acc_sensitive[1]) * 100.))\n",
    "    fpr, fnr, fpr_fnr_tpr_sensitive = compute_fpr_fnr(y_test.flatten(), y_pred_test.flatten(),\n",
    "                                                      s_test.flatten())\n",
    "    print('Encoder FPR and FNR: %.2f, %.2f' % (fpr * 100., fnr * 100.))\n",
    "    print(\"TPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[2, 0] * 100., fpr_fnr_tpr_sensitive[2, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[2, 0] - fpr_fnr_tpr_sensitive[2, 1]) * 100.))\n",
    "    print(\"FPR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[0, 0] * 100., fpr_fnr_tpr_sensitive[0, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[0, 0] - fpr_fnr_tpr_sensitive[0, 1]) * 100.))\n",
    "    print(\"FNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[1, 0] * 100., fpr_fnr_tpr_sensitive[1, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[1, 0] - fpr_fnr_tpr_sensitive[1, 1]) * 100.))\n",
    "    print(\"TNR per sensitive value: %.2f, %.2f, (%.2f)\" % (\n",
    "    fpr_fnr_tpr_sensitive[3, 0] * 100., fpr_fnr_tpr_sensitive[3, 1] * 100.,\n",
    "    (fpr_fnr_tpr_sensitive[3, 0] - fpr_fnr_tpr_sensitive[3, 1]) * 100.))\n",
    "\n",
    "    return True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cce2bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_all_models(seed):\n",
    "    models_dir = './models_{}/'.format(seed)\n",
    "    if os.path.exists(models_dir):\n",
    "        import shutil\n",
    "        shutil.rmtree(models_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "86ccb321",
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_files(seed):\n",
    "    file_dir = '.'\n",
    "    for f in os.listdir(file_dir):\n",
    "        if re.search(r\".*\\.csv\", f):\n",
    "            os.remove(os.path.join(file_dir, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "767d933c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Search Topic</th>\n",
       "      <th>Label</th>\n",
       "      <th>Ad ID</th>\n",
       "      <th>Ad Inferred Collation Group ID</th>\n",
       "      <th>Ad Is A Video</th>\n",
       "      <th>Ad Images</th>\n",
       "      <th>Ad Image Thumbnail</th>\n",
       "      <th>Ad Texts</th>\n",
       "      <th>Ad WAIST Targeting</th>\n",
       "      <th>Ad CTA (Call To Action)</th>\n",
       "      <th>...</th>\n",
       "      <th>Observer ID</th>\n",
       "      <th>Observer Age</th>\n",
       "      <th>Observer Gender</th>\n",
       "      <th>Observer Employment Status</th>\n",
       "      <th>Observer Indigeneity</th>\n",
       "      <th>Observer Language</th>\n",
       "      <th>Observer Income</th>\n",
       "      <th>Observer Party Preference</th>\n",
       "      <th>Observer Postcode</th>\n",
       "      <th>Observer Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_spotlight_1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Get the most out of Make it March with great d...</td>\n",
       "      <td>[{\"age_max\":\"53\",\"age_min\":\"6\",\"gender\":\"ANY\",...</td>\n",
       "      <td>Exclusions Apply</td>\n",
       "      <td>...</td>\n",
       "      <td>\"cd1e6b02e3b7e1213ff2ab76825da5b2\"</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>Male</td>\n",
       "      <td>Employed full time</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>English</td>\n",
       "      <td>$104,000 - $155,999</td>\n",
       "      <td>Other (please specify)</td>\n",
       "      <td>4122</td>\n",
       "      <td>Bachelor degree level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_australian_investment_educat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take this Quiz to find out</td>\n",
       "      <td>[{\"interest_code\":[{\"id\":\"6003143720966\",\"name...</td>\n",
       "      <td>Stock Market Quiz</td>\n",
       "      <td>...</td>\n",
       "      <td>\"648d457e9a02f732d1b38c1b77a9b881\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Retired</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>$52,000 - $64,999</td>\n",
       "      <td>Labor</td>\n",
       "      <td>4670</td>\n",
       "      <td>Year 12 or equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_australian_investment_educat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Don't buy another share if you can't answer t...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"location_type\":...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\"8886246e229184117f91c99c3f50911b\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Employed full time</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>$78,000 - $90,999</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>0810</td>\n",
       "      <td>Year 12 or equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_spotlight_2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BONUS $40 Instant Saving Coupon when you spend...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"location_type\":...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\"aad2c470a3e571f426843cc1e58a6e91\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>$26,000 - $33,799</td>\n",
       "      <td>Labor</td>\n",
       "      <td>4815</td>\n",
       "      <td>Bachelor degree level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_australian_investment_educat...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take this Quiz to find out</td>\n",
       "      <td>[{\"age_max\":\"52\",\"age_min\":\"20\",\"gender\":\"ANY\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\"922eea642dffa28500828e57eae57bd2\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Retired</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Other (please specify)</td>\n",
       "      <td>2904</td>\n",
       "      <td>Bachelor degree level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_bespoke_letterpress_20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4499</td>\n",
       "      <td>false</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Heirloom Recipe Books have been designed t...</td>\n",
       "      <td>[{\"business_id\":\"338873990021733\",\"ca_owner_na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\"4e6524432ef0beac7f011101998d3a16\"</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>false</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>4000</td>\n",
       "      <td>Prefer not to say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_commonwealth_bank_105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4532</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CommBank are proud to support the next generat...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"type\":\"LOCATION...</td>\n",
       "      <td>Hartley</td>\n",
       "      <td>...</td>\n",
       "      <td>\"5dc1e4044881082f4446b6a7e6610a62\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_riley_burnett_10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4533</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As one of the area's largest independent, fami...</td>\n",
       "      <td>[{\"age_max\":\"53\",\"age_min\":\"22\",\"gender\":\"FEMA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\"f30c0193d2ad3a76868055e080a9e433\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_myer_145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4534</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Get ready for sparkle season with your exclusi...</td>\n",
       "      <td>[{\"interest_code\":[{\"id\":\"6003263791114\",\"name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\"f30c0193d2ad3a76868055e080a9e433\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>Categories_Overall</td>\n",
       "      <td>categoriesoverall_awesome_maps_6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4535</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THE â€œthings to do before you dieâ€ list. Dis...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"type\":\"LOCATION...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>\"2882cf07f80daaa56183df852e217634\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2989 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Search Topic                                              Label  \\\n",
       "0     Categories_Overall                      categoriesoverall_spotlight_1   \n",
       "1     Categories_Overall  categoriesoverall_australian_investment_educat...   \n",
       "2     Categories_Overall  categoriesoverall_australian_investment_educat...   \n",
       "3     Categories_Overall                      categoriesoverall_spotlight_2   \n",
       "4     Categories_Overall  categoriesoverall_australian_investment_educat...   \n",
       "...                  ...                                                ...   \n",
       "2984  Categories_Overall           categoriesoverall_bespoke_letterpress_20   \n",
       "2985  Categories_Overall            categoriesoverall_commonwealth_bank_105   \n",
       "2986  Categories_Overall                 categoriesoverall_riley_burnett_10   \n",
       "2987  Categories_Overall                         categoriesoverall_myer_145   \n",
       "2988  Categories_Overall                   categoriesoverall_awesome_maps_6   \n",
       "\n",
       "     Ad ID Ad Inferred Collation Group ID Ad Is A Video  \\\n",
       "0      NaN                              0          true   \n",
       "1      NaN                              0          true   \n",
       "2      NaN                              0          true   \n",
       "3      NaN                              0         false   \n",
       "4      NaN                              0          true   \n",
       "...    ...                            ...           ...   \n",
       "2984   NaN                           4499         false   \n",
       "2985   NaN                           4532          true   \n",
       "2986   NaN                           4533          true   \n",
       "2987   NaN                           4534          true   \n",
       "2988   NaN                           4535          true   \n",
       "\n",
       "                                              Ad Images Ad Image Thumbnail  \\\n",
       "0     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "1     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "3     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "4     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "...                                                 ...                ...   \n",
       "2984  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2985  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2986  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2987  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2988  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "\n",
       "                                               Ad Texts  \\\n",
       "0     Get the most out of Make it March with great d...   \n",
       "1                            Take this Quiz to find out   \n",
       "2      Don't buy another share if you can't answer t...   \n",
       "3     BONUS $40 Instant Saving Coupon when you spend...   \n",
       "4                            Take this Quiz to find out   \n",
       "...                                                 ...   \n",
       "2984  Our Heirloom Recipe Books have been designed t...   \n",
       "2985  CommBank are proud to support the next generat...   \n",
       "2986  As one of the area's largest independent, fami...   \n",
       "2987  Get ready for sparkle season with your exclusi...   \n",
       "2988  THE â€œthings to do before you dieâ€ list. Dis...   \n",
       "\n",
       "                                     Ad WAIST Targeting  \\\n",
       "0     [{\"age_max\":\"53\",\"age_min\":\"6\",\"gender\":\"ANY\",...   \n",
       "1     [{\"interest_code\":[{\"id\":\"6003143720966\",\"name...   \n",
       "2     [{\"location_name\":\"Australia\",\"location_type\":...   \n",
       "3     [{\"location_name\":\"Australia\",\"location_type\":...   \n",
       "4     [{\"age_max\":\"52\",\"age_min\":\"20\",\"gender\":\"ANY\"...   \n",
       "...                                                 ...   \n",
       "2984  [{\"business_id\":\"338873990021733\",\"ca_owner_na...   \n",
       "2985  [{\"location_name\":\"Australia\",\"type\":\"LOCATION...   \n",
       "2986  [{\"age_max\":\"53\",\"age_min\":\"22\",\"gender\":\"FEMA...   \n",
       "2987  [{\"interest_code\":[{\"id\":\"6003263791114\",\"name...   \n",
       "2988  [{\"location_name\":\"Australia\",\"type\":\"LOCATION...   \n",
       "\n",
       "     Ad CTA (Call To Action)  ...                         Observer ID  \\\n",
       "0           Exclusions Apply  ...  \"cd1e6b02e3b7e1213ff2ab76825da5b2\"   \n",
       "1          Stock Market Quiz  ...  \"648d457e9a02f732d1b38c1b77a9b881\"   \n",
       "2                        NaN  ...  \"8886246e229184117f91c99c3f50911b\"   \n",
       "3                        NaN  ...  \"aad2c470a3e571f426843cc1e58a6e91\"   \n",
       "4                        NaN  ...  \"922eea642dffa28500828e57eae57bd2\"   \n",
       "...                      ...  ...                                 ...   \n",
       "2984                     NaN  ...  \"4e6524432ef0beac7f011101998d3a16\"   \n",
       "2985                 Hartley  ...  \"5dc1e4044881082f4446b6a7e6610a62\"   \n",
       "2986                     NaN  ...  \"f30c0193d2ad3a76868055e080a9e433\"   \n",
       "2987                     NaN  ...  \"f30c0193d2ad3a76868055e080a9e433\"   \n",
       "2988                     NaN  ...  \"2882cf07f80daaa56183df852e217634\"   \n",
       "\n",
       "           Observer Age    Observer Gender Observer Employment Status  \\\n",
       "0               45 - 54               Male         Employed full time   \n",
       "1               55 - 64               Male                    Retired   \n",
       "2               55 - 64               Male         Employed full time   \n",
       "3               55 - 64             Female          Prefer not to say   \n",
       "4               55 - 64               Male                    Retired   \n",
       "...                 ...                ...                        ...   \n",
       "2984  Prefer not to say  Prefer not to say          Prefer not to say   \n",
       "2985                NaN                NaN                        NaN   \n",
       "2986                NaN                NaN                        NaN   \n",
       "2987                NaN                NaN                        NaN   \n",
       "2988                NaN                NaN                        NaN   \n",
       "\n",
       "     Observer Indigeneity  Observer Language      Observer Income  \\\n",
       "0                 UNKNOWN            English  $104,000 - $155,999   \n",
       "1                   false            English    $52,000 - $64,999   \n",
       "2                   false            English    $78,000 - $90,999   \n",
       "3                   false            English    $26,000 - $33,799   \n",
       "4                   false            English    Prefer not to say   \n",
       "...                   ...                ...                  ...   \n",
       "2984                false  Prefer not to say    Prefer not to say   \n",
       "2985                  NaN                NaN                  NaN   \n",
       "2986                  NaN                NaN                  NaN   \n",
       "2987                  NaN                NaN                  NaN   \n",
       "2988                  NaN                NaN                  NaN   \n",
       "\n",
       "     Observer Party Preference Observer Postcode     Observer Education  \n",
       "0       Other (please specify)              4122  Bachelor degree level  \n",
       "1                        Labor              4670  Year 12 or equivalent  \n",
       "2            Prefer not to say              0810  Year 12 or equivalent  \n",
       "3                        Labor              4815  Bachelor degree level  \n",
       "4       Other (please specify)              2904  Bachelor degree level  \n",
       "...                        ...               ...                    ...  \n",
       "2984         Prefer not to say              4000      Prefer not to say  \n",
       "2985                       NaN               NaN                    NaN  \n",
       "2986                       NaN               NaN                    NaN  \n",
       "2987                       NaN               NaN                    NaN  \n",
       "2988                       NaN               NaN                    NaN  \n",
       "\n",
       "[2989 rows x 27 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/Categories_Overall.xlsx', dtype=object)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a4b33f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ad Inferred Collation Group ID</th>\n",
       "      <th>Ad Is A Video</th>\n",
       "      <th>Ad Images</th>\n",
       "      <th>Ad Image Thumbnail</th>\n",
       "      <th>Ad Texts</th>\n",
       "      <th>Ad WAIST Targeting</th>\n",
       "      <th>Ad CTA (Call To Action)</th>\n",
       "      <th>Ad Library Link</th>\n",
       "      <th>Australian Ad Observatory Link</th>\n",
       "      <th>Advertiser</th>\n",
       "      <th>...</th>\n",
       "      <th>Observer ID</th>\n",
       "      <th>Observer Age</th>\n",
       "      <th>Observer Gender</th>\n",
       "      <th>Observer Employment Status</th>\n",
       "      <th>Observer Indigeneity</th>\n",
       "      <th>Observer Language</th>\n",
       "      <th>Observer Income</th>\n",
       "      <th>Observer Party Preference</th>\n",
       "      <th>Observer Postcode</th>\n",
       "      <th>Observer Education</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Get the most out of Make it March with great d...</td>\n",
       "      <td>[{\"age_max\":\"53\",\"age_min\":\"6\",\"gender\":\"ANY\",...</td>\n",
       "      <td>Exclusions Apply</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>...</td>\n",
       "      <td>\"cd1e6b02e3b7e1213ff2ab76825da5b2\"</td>\n",
       "      <td>45 - 54</td>\n",
       "      <td>Male</td>\n",
       "      <td>Employed full time</td>\n",
       "      <td>UNKNOWN</td>\n",
       "      <td>English</td>\n",
       "      <td>$104,000 - $155,999</td>\n",
       "      <td>Other (please specify)</td>\n",
       "      <td>4122</td>\n",
       "      <td>Bachelor degree level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take this Quiz to find out</td>\n",
       "      <td>[{\"interest_code\":[{\"id\":\"6003143720966\",\"name...</td>\n",
       "      <td>Stock Market Quiz</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Australian Investment Education</td>\n",
       "      <td>...</td>\n",
       "      <td>\"648d457e9a02f732d1b38c1b77a9b881\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Retired</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>$52,000 - $64,999</td>\n",
       "      <td>Labor</td>\n",
       "      <td>4670</td>\n",
       "      <td>Year 12 or equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Don't buy another share if you can't answer t...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"location_type\":...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Australian Investment Education</td>\n",
       "      <td>...</td>\n",
       "      <td>\"8886246e229184117f91c99c3f50911b\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Employed full time</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>$78,000 - $90,999</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>0810</td>\n",
       "      <td>Year 12 or equivalent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>false</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>BONUS $40 Instant Saving Coupon when you spend...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"location_type\":...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>...</td>\n",
       "      <td>\"aad2c470a3e571f426843cc1e58a6e91\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Female</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>$26,000 - $33,799</td>\n",
       "      <td>Labor</td>\n",
       "      <td>4815</td>\n",
       "      <td>Bachelor degree level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Take this Quiz to find out</td>\n",
       "      <td>[{\"age_max\":\"52\",\"age_min\":\"20\",\"gender\":\"ANY\"...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Australian Investment Education</td>\n",
       "      <td>...</td>\n",
       "      <td>\"922eea642dffa28500828e57eae57bd2\"</td>\n",
       "      <td>55 - 64</td>\n",
       "      <td>Male</td>\n",
       "      <td>Retired</td>\n",
       "      <td>false</td>\n",
       "      <td>English</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Other (please specify)</td>\n",
       "      <td>2904</td>\n",
       "      <td>Bachelor degree level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2984</th>\n",
       "      <td>4499</td>\n",
       "      <td>false</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Heirloom Recipe Books have been designed t...</td>\n",
       "      <td>[{\"business_id\":\"338873990021733\",\"ca_owner_na...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Bespoke Letterpress</td>\n",
       "      <td>...</td>\n",
       "      <td>\"4e6524432ef0beac7f011101998d3a16\"</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>false</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>4000</td>\n",
       "      <td>Prefer not to say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2985</th>\n",
       "      <td>4532</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CommBank are proud to support the next generat...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"type\":\"LOCATION...</td>\n",
       "      <td>Hartley</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Commonwealth Bank</td>\n",
       "      <td>...</td>\n",
       "      <td>\"5dc1e4044881082f4446b6a7e6610a62\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2986</th>\n",
       "      <td>4533</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As one of the area's largest independent, fami...</td>\n",
       "      <td>[{\"age_max\":\"53\",\"age_min\":\"22\",\"gender\":\"FEMA...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Riley Burnett</td>\n",
       "      <td>...</td>\n",
       "      <td>\"f30c0193d2ad3a76868055e080a9e433\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2987</th>\n",
       "      <td>4534</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Get ready for sparkle season with your exclusi...</td>\n",
       "      <td>[{\"interest_code\":[{\"id\":\"6003263791114\",\"name...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>MYER</td>\n",
       "      <td>...</td>\n",
       "      <td>\"f30c0193d2ad3a76868055e080a9e433\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2988</th>\n",
       "      <td>4535</td>\n",
       "      <td>true</td>\n",
       "      <td>https://fta-image-quickview.s3.ap-southeast-2....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>THE â€œthings to do before you dieâ€ list. Dis...</td>\n",
       "      <td>[{\"location_name\":\"Australia\",\"type\":\"LOCATION...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.facebook.com/ads/library/?active_s...</td>\n",
       "      <td>https://fta-quickview.s3.ap-southeast-2.amazon...</td>\n",
       "      <td>Awesome Maps</td>\n",
       "      <td>...</td>\n",
       "      <td>\"2882cf07f80daaa56183df852e217634\"</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2989 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Ad Inferred Collation Group ID Ad Is A Video  \\\n",
       "0                                 0          true   \n",
       "1                                 0          true   \n",
       "2                                 0          true   \n",
       "3                                 0         false   \n",
       "4                                 0          true   \n",
       "...                             ...           ...   \n",
       "2984                           4499         false   \n",
       "2985                           4532          true   \n",
       "2986                           4533          true   \n",
       "2987                           4534          true   \n",
       "2988                           4535          true   \n",
       "\n",
       "                                              Ad Images Ad Image Thumbnail  \\\n",
       "0     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "1     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "3     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "4     https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "...                                                 ...                ...   \n",
       "2984  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2985  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2986  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2987  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "2988  https://fta-image-quickview.s3.ap-southeast-2....                NaN   \n",
       "\n",
       "                                               Ad Texts  \\\n",
       "0     Get the most out of Make it March with great d...   \n",
       "1                            Take this Quiz to find out   \n",
       "2      Don't buy another share if you can't answer t...   \n",
       "3     BONUS $40 Instant Saving Coupon when you spend...   \n",
       "4                            Take this Quiz to find out   \n",
       "...                                                 ...   \n",
       "2984  Our Heirloom Recipe Books have been designed t...   \n",
       "2985  CommBank are proud to support the next generat...   \n",
       "2986  As one of the area's largest independent, fami...   \n",
       "2987  Get ready for sparkle season with your exclusi...   \n",
       "2988  THE â€œthings to do before you dieâ€ list. Dis...   \n",
       "\n",
       "                                     Ad WAIST Targeting  \\\n",
       "0     [{\"age_max\":\"53\",\"age_min\":\"6\",\"gender\":\"ANY\",...   \n",
       "1     [{\"interest_code\":[{\"id\":\"6003143720966\",\"name...   \n",
       "2     [{\"location_name\":\"Australia\",\"location_type\":...   \n",
       "3     [{\"location_name\":\"Australia\",\"location_type\":...   \n",
       "4     [{\"age_max\":\"52\",\"age_min\":\"20\",\"gender\":\"ANY\"...   \n",
       "...                                                 ...   \n",
       "2984  [{\"business_id\":\"338873990021733\",\"ca_owner_na...   \n",
       "2985  [{\"location_name\":\"Australia\",\"type\":\"LOCATION...   \n",
       "2986  [{\"age_max\":\"53\",\"age_min\":\"22\",\"gender\":\"FEMA...   \n",
       "2987  [{\"interest_code\":[{\"id\":\"6003263791114\",\"name...   \n",
       "2988  [{\"location_name\":\"Australia\",\"type\":\"LOCATION...   \n",
       "\n",
       "     Ad CTA (Call To Action)  \\\n",
       "0           Exclusions Apply   \n",
       "1          Stock Market Quiz   \n",
       "2                        NaN   \n",
       "3                        NaN   \n",
       "4                        NaN   \n",
       "...                      ...   \n",
       "2984                     NaN   \n",
       "2985                 Hartley   \n",
       "2986                     NaN   \n",
       "2987                     NaN   \n",
       "2988                     NaN   \n",
       "\n",
       "                                        Ad Library Link  \\\n",
       "0     https://www.facebook.com/ads/library/?active_s...   \n",
       "1     https://www.facebook.com/ads/library/?active_s...   \n",
       "2     https://www.facebook.com/ads/library/?active_s...   \n",
       "3     https://www.facebook.com/ads/library/?active_s...   \n",
       "4     https://www.facebook.com/ads/library/?active_s...   \n",
       "...                                                 ...   \n",
       "2984  https://www.facebook.com/ads/library/?active_s...   \n",
       "2985  https://www.facebook.com/ads/library/?active_s...   \n",
       "2986  https://www.facebook.com/ads/library/?active_s...   \n",
       "2987  https://www.facebook.com/ads/library/?active_s...   \n",
       "2988  https://www.facebook.com/ads/library/?active_s...   \n",
       "\n",
       "                         Australian Ad Observatory Link  \\\n",
       "0     https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "1     https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "2     https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "3     https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "4     https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "...                                                 ...   \n",
       "2984  https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "2985  https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "2986  https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "2987  https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "2988  https://fta-quickview.s3.ap-southeast-2.amazon...   \n",
       "\n",
       "                           Advertiser  ...  \\\n",
       "0                           Spotlight  ...   \n",
       "1     Australian Investment Education  ...   \n",
       "2     Australian Investment Education  ...   \n",
       "3                           Spotlight  ...   \n",
       "4     Australian Investment Education  ...   \n",
       "...                               ...  ...   \n",
       "2984              Bespoke Letterpress  ...   \n",
       "2985                Commonwealth Bank  ...   \n",
       "2986                    Riley Burnett  ...   \n",
       "2987                             MYER  ...   \n",
       "2988                     Awesome Maps  ...   \n",
       "\n",
       "                             Observer ID       Observer Age  \\\n",
       "0     \"cd1e6b02e3b7e1213ff2ab76825da5b2\"            45 - 54   \n",
       "1     \"648d457e9a02f732d1b38c1b77a9b881\"            55 - 64   \n",
       "2     \"8886246e229184117f91c99c3f50911b\"            55 - 64   \n",
       "3     \"aad2c470a3e571f426843cc1e58a6e91\"            55 - 64   \n",
       "4     \"922eea642dffa28500828e57eae57bd2\"            55 - 64   \n",
       "...                                  ...                ...   \n",
       "2984  \"4e6524432ef0beac7f011101998d3a16\"  Prefer not to say   \n",
       "2985  \"5dc1e4044881082f4446b6a7e6610a62\"                NaN   \n",
       "2986  \"f30c0193d2ad3a76868055e080a9e433\"                NaN   \n",
       "2987  \"f30c0193d2ad3a76868055e080a9e433\"                NaN   \n",
       "2988  \"2882cf07f80daaa56183df852e217634\"                NaN   \n",
       "\n",
       "        Observer Gender Observer Employment Status Observer Indigeneity  \\\n",
       "0                  Male         Employed full time              UNKNOWN   \n",
       "1                  Male                    Retired                false   \n",
       "2                  Male         Employed full time                false   \n",
       "3                Female          Prefer not to say                false   \n",
       "4                  Male                    Retired                false   \n",
       "...                 ...                        ...                  ...   \n",
       "2984  Prefer not to say          Prefer not to say                false   \n",
       "2985                NaN                        NaN                  NaN   \n",
       "2986                NaN                        NaN                  NaN   \n",
       "2987                NaN                        NaN                  NaN   \n",
       "2988                NaN                        NaN                  NaN   \n",
       "\n",
       "      Observer Language      Observer Income Observer Party Preference  \\\n",
       "0               English  $104,000 - $155,999    Other (please specify)   \n",
       "1               English    $52,000 - $64,999                     Labor   \n",
       "2               English    $78,000 - $90,999         Prefer not to say   \n",
       "3               English    $26,000 - $33,799                     Labor   \n",
       "4               English    Prefer not to say    Other (please specify)   \n",
       "...                 ...                  ...                       ...   \n",
       "2984  Prefer not to say    Prefer not to say         Prefer not to say   \n",
       "2985                NaN                  NaN                       NaN   \n",
       "2986                NaN                  NaN                       NaN   \n",
       "2987                NaN                  NaN                       NaN   \n",
       "2988                NaN                  NaN                       NaN   \n",
       "\n",
       "     Observer Postcode     Observer Education  \n",
       "0                 4122  Bachelor degree level  \n",
       "1                 4670  Year 12 or equivalent  \n",
       "2                 0810  Year 12 or equivalent  \n",
       "3                 4815  Bachelor degree level  \n",
       "4                 2904  Bachelor degree level  \n",
       "...                ...                    ...  \n",
       "2984              4000      Prefer not to say  \n",
       "2985               NaN                    NaN  \n",
       "2986               NaN                    NaN  \n",
       "2987               NaN                    NaN  \n",
       "2988               NaN                    NaN  \n",
       "\n",
       "[2989 rows x 24 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop('Search Topic', axis=1)\n",
    "data = data.drop('Label', axis=1)\n",
    "data = data.drop('Ad ID', axis=1)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02542e29",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
